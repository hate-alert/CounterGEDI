{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-92ae64a6dc1e>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-92ae64a6dc1e>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    https://github.com/monologg/GoEmotions-pytorch\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### for emotion detection\n",
    "https://github.com/monologg/GoEmotions-pytorch\n",
    "### For toxicity detection\n",
    "perspective api\n",
    "### For politeness detection\n",
    "https://github.com/AlafateABULIMITI/politeness-detection\n",
    "### For language quality\n",
    "https://github.com/WanzhengZhu/GPS/blob/master/language_quality.py\n",
    "### Other metrics are aleady added add two metric from the GPS model.\n",
    "### Implement GPS model as a baseline.\n",
    "save_path='../HULK_new/Counterspeech/Saved_Models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../Generation\")\n",
    "sys.path.append('../Generation/eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import json\n",
    "from loguru import logger\n",
    "import pandas as pd \n",
    "from eval import *\n",
    "path_datasets = '/home/adarsh-binny' + '/HULK_new/Counterspeech/Datasets'\n",
    "path_result   = '/home/adarsh-binny' + '/HULK_new/Counterspeech/Results_new'\n",
    "path_result1   = '/home/adarsh-binny' + '/HULK_new/Counterspeech/Results'\n",
    "save_path     = '/home/adarsh-binny' + '/HULK_new/Counterspeech/metrics_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from model import BertForMultiLabelClassification\n",
    "from multilabel_pipeline import MultiLabelPipeline\n",
    "from pprint import pprint\n",
    "\n",
    "cache_dir='/home/adarsh-binny/HULK_new/Saved_models'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"monologg/bert-base-cased-goemotions-ekman\",cache_dir=cache_dir)\n",
    "model = BertForMultiLabelClassification.from_pretrained(\"monologg/bert-base-cased-goemotions-ekman\",cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from torch import cuda\n",
    "\n",
    "VALID_BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PDataset(Dataset):\n",
    "    def __init__(self, hypo, tokenizer, max_len=200):\n",
    "        self.len = len(hypo)\n",
    "        self.data = hypo\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        text = self.data[index]\n",
    "        #print(text)\n",
    "        text = \" \".join(text.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def goemotion(hypo):\n",
    "    N =len(hypo)\n",
    "    print(\"Length of Hypothesis: \", N)\n",
    "    hypo_ = PDataset(hypo, tokenizer, 200)\n",
    "    testing_loader = DataLoader(hypo_, **test_params)\n",
    "    model.eval()\n",
    "    tr_loss = 0\n",
    "    n_correct = 0 \n",
    "    n_wrong = 0\n",
    "    total = {\"joy\":0, \"fear\":0, \"anger\":0, \"love\":0, \"surprise\":0, \"sadness\":0};\n",
    "    n1 = N//8\n",
    "    if N%VALID_BATCH_SIZE!=0:\n",
    "        n1+=1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with tqdm(n1) as pbar:\n",
    "            for _, data in enumerate(testing_loader, 0):\n",
    "                #print(data)\n",
    "                ids = data['ids'].to(device, dtype = torch.long)\n",
    "                mask = data['mask'].to(device, dtype = torch.long)\n",
    "                outputs = model(ids, mask)[0]\n",
    "                #print(outputs.shape)\n",
    "                #print(outputs)\n",
    "                outputs = torch.nn.Sigmoid()(outputs).to('cpu').numpy()\n",
    "                #print(outputs)\n",
    "                for scores in outputs:\n",
    "                    #print(scores)\n",
    "                    for idx, s in enumerate(scores):\n",
    "                        if model.config.id2label[idx] in [\"joy\", \"fear\", \"anger\", \"love\", \"surprise\", \"sadness\"]:\n",
    "                            total[model.config.id2label[idx]]+=s\n",
    "                pbar.update()\n",
    "    for i in total.keys():\n",
    "        total[i]/=N\n",
    "    return total\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Hypothesis:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adarsh-binny/.conda/envs/csgen/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "1it [00:00,  4.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'joy': 0.5809454414993525,\n",
       " 'fear': 0.0017176893597934395,\n",
       " 'anger': 0.1949171123560518,\n",
       " 'love': 0.0,\n",
       " 'surprise': 0.1574256321764551,\n",
       " 'sadness': 0.009181847679428756}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    \n",
    "    \"Hey that's a thought! Maybe we need [NAME] to be the celebrity vaccine endorsement!\",\n",
    "    \"itâ€™s happened before?! love my hometown of beautiful new ken ðŸ˜‚ðŸ˜‚\",\n",
    "    \"I love you, brother.\",\n",
    "    \"Troll, bro. They know they're saying stupid shit. The motherfucker does nothing but stink up libertarian subs talking shit\",\n",
    "]\n",
    "\n",
    "goemotion(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_emotion(hypo, emotion, normal=False):\n",
    "    scores = goemotion(hypo)\n",
    "    #print(scores)\n",
    "    if normal==False:\n",
    "        return scores[emotion]\n",
    "    else:\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 25.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Hypothesis:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1949171123560518"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    \n",
    "    \"Hey that's a thought! Maybe we need [NAME] to be the celebrity vaccine endorsement!\",\n",
    "    \"itâ€™s happened before?! love my hometown of beautiful new ken ðŸ˜‚ðŸ˜‚\",\n",
    "    \"I love you, brother.\",\n",
    "    \"Troll, bro. They know they're saying stupid shit. The motherfucker does nothing but stink up libertarian subs talking shit\",\n",
    "]\n",
    "\n",
    "calc_emotion(texts, \"anger\", normal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(trained_on,tested_on):\n",
    "    train_path = glob.glob(path_datasets+'/*'+trained_on+'*/*rain*')[0]\n",
    "    gen        = glob.glob(path_result+'/*'+trained_on+'*'+tested_on+'*1628*')\n",
    "    ref        = glob.glob(path_result1+'/*'+tested_on+'*'+'references'+'*')[0]\n",
    "    \n",
    "#     print(gen,ref)\n",
    "    with open(ref, 'r') as file:\n",
    "        ref_dict   = json.loads(file.read())\n",
    "        \n",
    "    scores = {}\n",
    "    for files in gen:\n",
    "        with open(files, 'r') as file:\n",
    "            gen_dict  = json.loads(file.read())\n",
    "        emotion = gen_dict['params']['task_name'][0][1]\n",
    "        #print(files)\n",
    "        #print(emotion)\n",
    "        if (\"Emotion\" in gen_dict['params']['task_name'][0][0] or \"gedi\" not in files)==False:\n",
    "            continue\n",
    "        print(files)\n",
    "        gpu_id    = gen_dict['params']['gpu_id']\n",
    "        hypo = []\n",
    "        refs = []\n",
    "        signature = files.split(\"_\")[-1].split(\".\")[0]\n",
    "        for key in gen_dict['samples']:\n",
    "            for sentences in gen_dict['samples'][key]['counterspeech_model']:\n",
    "                hypo.append(sentences)\n",
    "                refs.append(ref_dict['samples'][key]['counterspeech_model'])\n",
    "        \n",
    "        train = pd.read_csv(train_path)\n",
    "        train_set = list(zip(train['initiator_message'].tolist(),train['reply_message'].tolist()))\n",
    "        params = hypo\n",
    "        if \"gedi\" not in files:\n",
    "            average_scores = calc_emotion(hypo, \"\", normal=True)\n",
    "            key = trained_on+'_'+tested_on+'_'+emotion+'_'+signature+'_'+str(gpu_id)\n",
    "            scores[key] = average_scores\n",
    "            print(\"Scores:\\n\",average_scores)\n",
    "            print()\n",
    "        else:\n",
    "            print(emotion)\n",
    "            average_score = calc_emotion(hypo, emotion)\n",
    "            key = trained_on+'_'+tested_on+'_'+emotion+'_'+signature+'_'+str(gpu_id)\n",
    "            scores[key] = average_score\n",
    "            print(emotion, \"Score:\",average_score)\n",
    "            print()\n",
    "    json.dump(scores, open(save_path +tested_on+'emotion.json','w'),indent = 4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(trained_on,tested_on):\n",
    "    train_path = glob.glob(path_datasets+'/*'+trained_on+'*/*rain*')[0]\n",
    "    gen        = glob.glob(path_result+'/*'+trained_on+'*'+tested_on+'*16*_multi*')\n",
    "    ref        = glob.glob(path_result1+'/*'+tested_on+'*'+'references'+'*')[0]\n",
    "    \n",
    "#     print(gen,ref)\n",
    "    with open(ref, 'r') as file:\n",
    "        ref_dict   = json.loads(file.read())\n",
    "        \n",
    "    scores = {}\n",
    "    for files in gen:\n",
    "        with open(files, 'r') as file:\n",
    "            gen_dict  = json.loads(file.read())\n",
    "        emotion = gen_dict['params']['task_name'][0][1]\n",
    "        #print(files)\n",
    "        emotion = \"fear\"\n",
    "        print(gen_dict['params']['task_name'])\n",
    "        print(gen_dict['params']['disc_weight'])\n",
    "        #print(emotion)\n",
    "        #if (\"Emotion\" in gen_dict['params']['task_name'][0][0] or \"gedi\" not in files)==False:\n",
    "        #    continue\n",
    "        if [['Toxicity', 'toxic'], ['Politeness', 'polite']]!=gen_dict['params']['task_name']:\n",
    "            continue\n",
    "        \n",
    "        print(files)\n",
    "        gpu_id    = gen_dict['params']['gpu_id']\n",
    "        hypo = []\n",
    "        refs = []\n",
    "        signature = files.split(\"_\")[-1].split(\".\")[0]\n",
    "        for key in gen_dict['samples']:\n",
    "            for sentences in gen_dict['samples'][key]['counterspeech_model']:\n",
    "                hypo.append(sentences)\n",
    "                refs.append(ref_dict['samples'][key]['counterspeech_model'])\n",
    "        \n",
    "        train = pd.read_csv(train_path)\n",
    "        train_set = list(zip(train['initiator_message'].tolist(),train['reply_message'].tolist()))\n",
    "        params = hypo\n",
    "        if \"gedi\" not in files:\n",
    "            average_scores = calc_emotion(hypo, \"\", normal=True)\n",
    "            key = trained_on+'_'+tested_on+'_'+emotion+'_'+signature+'_'+str(gpu_id)\n",
    "            scores[key] = average_scores\n",
    "            print(\"Scores:\\n\",average_scores)\n",
    "            print()\n",
    "        else:\n",
    "            print(emotion)\n",
    "            average_score = calc_emotion(hypo, emotion)\n",
    "            key = trained_on+'_'+tested_on+'_'+emotion+'_'+signature+'_'+str(gpu_id)\n",
    "            scores[key] = average_score\n",
    "            print(emotion, \"Score:\",average_score)\n",
    "            print()\n",
    "    #json.dump(scores, open(save_path +tested_on+'emotion.json','w'),indent = 4)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Reddit****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Emotion', 'sadness'], ['Politeness', 'polite']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'anger'], ['Politeness', 'polite'], ['Toxicity', 'toxic']]\n",
      "[0.4, 0.3, 0.3]\n",
      "[['Emotion', 'fear'], ['Politeness', 'polite']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'anger'], ['Toxicity', 'toxic']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'joy'], ['Politeness', 'polite'], ['Toxicity', 'toxic']]\n",
      "[0.4, 0.3, 0.3]\n",
      "[['Emotion', 'fear'], ['Toxicity', 'toxic']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'joy'], ['Toxicity', 'toxic']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'sadness'], ['Toxicity', 'toxic']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'fear'], ['Politeness', 'polite'], ['Toxicity', 'toxic']]\n",
      "[0.4, 0.3, 0.3]\n",
      "[['Emotion', 'anger'], ['Politeness', 'polite']]\n",
      "[0.5, 0.5]\n",
      "[['Toxicity', 'toxic'], ['Politeness', 'polite']]\n",
      "[0.5, 0.5]\n",
      "/home/adarsh-binny/HULK_new/Counterspeech/Results_new/Generator-CONAN_DialoGPT-medium_on_CONAN_gedi_huggingface_1629965093_multi.json\n",
      "fear\n",
      "Length of Hypothesis:  1120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70it [00:14,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear Score: 0.009005626851675125\n",
      "\n",
      "[['Emotion', 'joy'], ['Politeness', 'polite']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'sadness'], ['Politeness', 'polite'], ['Toxicity', 'toxic']]\n",
      "[0.4, 0.3, 0.3]\n",
      "[['Emotion', 'fear'], ['Politeness', 'polite']]\n",
      "[0.4, 0.3, 0.3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics('CONAN','CONAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Emotion', 'fear'], ['Politeness', 'polite']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'anger'], ['Politeness', 'polite'], ['Toxicity', 'toxic']]\n",
      "[0.4, 0.3, 0.3]\n",
      "[['Emotion', 'anger'], ['Toxicity', 'toxic']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'sadness'], ['Politeness', 'polite'], ['Toxicity', 'toxic']]\n",
      "[0.4, 0.3, 0.3]\n",
      "[['Emotion', 'joy'], ['Toxicity', 'toxic']]\n",
      "[0.5, 0.5]\n",
      "[['Toxicity', 'toxic'], ['Politeness', 'polite']]\n",
      "[0.5, 0.5]\n",
      "/home/adarsh-binny/HULK_new/Counterspeech/Results_new/Generator-Reddit_DialoGPT-medium_on_Reddit_gedi_huggingface_1629982885_multi.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear\n",
      "Length of Hypothesis:  6495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "406it [01:48,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear Score: 0.0021131527654708704\n",
      "\n",
      "[['Emotion', 'joy'], ['Politeness', 'polite'], ['Toxicity', 'toxic']]\n",
      "[0.4, 0.3, 0.3]\n",
      "[['Emotion', 'anger'], ['Politeness', 'polite']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'joy'], ['Politeness', 'polite']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'fear'], ['Politeness', 'polite'], ['Toxicity', 'toxic']]\n",
      "[0.4, 0.3, 0.3]\n",
      "[['Emotion', 'sadness'], ['Toxicity', 'toxic']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'sadness'], ['Politeness', 'polite']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'fear'], ['Toxicity', 'toxic']]\n",
      "[0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "metrics('Reddit','Reddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Emotion', 'fear'], ['Politeness', 'polite']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'joy'], ['Toxicity', 'toxic']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'sadness'], ['Politeness', 'polite']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'joy'], ['Politeness', 'polite'], ['Toxicity', 'toxic']]\n",
      "[0.4, 0.3, 0.3]\n",
      "[['Emotion', 'sadness'], ['Politeness', 'polite'], ['Toxicity', 'toxic']]\n",
      "[0.4, 0.3, 0.3]\n",
      "[['Emotion', 'fear'], ['Politeness', 'polite'], ['Toxicity', 'toxic']]\n",
      "[0.4, 0.3, 0.3]\n",
      "[['Emotion', 'anger'], ['Politeness', 'polite']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'anger'], ['Politeness', 'polite'], ['Toxicity', 'toxic']]\n",
      "[0.4, 0.3, 0.3]\n",
      "[['Emotion', 'anger'], ['Toxicity', 'toxic']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'joy'], ['Politeness', 'polite']]\n",
      "[0.5, 0.5]\n",
      "[['Toxicity', 'toxic'], ['Politeness', 'polite']]\n",
      "[0.5, 0.5]\n",
      "/home/adarsh-binny/HULK_new/Counterspeech/Results_new/Generator-Gab_DialoGPT-medium_on_Gab_gedi_huggingface_1630031392_multi.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear\n",
      "Length of Hypothesis:  18115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1133it [07:32,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear Score: 0.002000224312458338\n",
      "\n",
      "[['Emotion', 'sadness'], ['Toxicity', 'toxic']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'fear'], ['Toxicity', 'toxic']]\n",
      "[0.5, 0.5]\n",
      "[['Emotion', 'sadness'], ['Politeness', 'polite'], ['Toxicity', 'toxic']]\n",
      "[0.4, 0.3, 0.3]\n"
     ]
    }
   ],
   "source": [
    "metrics('Gab', 'Gab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
