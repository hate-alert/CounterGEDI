{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Informativeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../HULK/Counterspeech/Datasets/Toxicity/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_labels=pd.read_csv('../HULK/Counterspeech/Datasets/Toxicity/test_labels.csv')\n",
    "df_test=pd.read_csv('../HULK/Counterspeech/Datasets/Toxicity/test.csv')\n",
    "\n",
    "\n",
    "\n",
    "df_test=df_test.merge(df_test_labels, left_on='id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_head=[]\n",
    "for index,row in df_test.iterrows():\n",
    "    tuple_temp=[row['id'], row['comment_text']]\n",
    "    flag=0\n",
    "    for ele in list(df.columns[2:]):\n",
    "        if(row[ele]==1):\n",
    "            tuple_temp.append('toxic')\n",
    "            flag=1\n",
    "            break\n",
    "    if(flag==0):\n",
    "        tuple_temp.append('non_toxic')\n",
    "    tuple_head.append(tuple_temp)\n",
    "df_new_test=pd.DataFrame(tuple_head,columns=['id','text','labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_head=[]\n",
    "for index,row in df.iterrows():\n",
    "    tuple_temp=[row['id'], row['comment_text']]\n",
    "    flag=0\n",
    "    for ele in list(df.columns[2:]):\n",
    "        if(row[ele]==1):\n",
    "            tuple_temp.append('toxic')\n",
    "            flag=1\n",
    "            break\n",
    "    if(flag==0):\n",
    "        tuple_temp.append('non_toxic')\n",
    "    tuple_head.append(tuple_temp)\n",
    "df_new=pd.DataFrame(tuple_head,columns=['id','text','labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_test_split(df_new, test_size=0.1,random_state=42,stratify=df_new['labels'])\n",
    "X_train.to_csv('../HULK/Counterspeech/Datasets/Toxicity/Train.csv',index=False)\n",
    "X_val.to_csv('../HULK/Counterspeech/Datasets/Toxicity/Val.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_test.to_csv('../HULK/Counterspeech/Datasets/Toxicity/Test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polite=pd.read_csv('../HULK/Counterspeech/Datasets/Politeness/politeness.tsv',sep='\\t')\n",
    "df_polite.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_head=[]\n",
    "for index,row in df_polite[df_polite['split']=='train'].iterrows():\n",
    "    tuple_temp=[row['txt']]\n",
    "    if(row['style']=='P_9'):\n",
    "        tuple_temp.append('polite')\n",
    "    else:\n",
    "        tuple_temp.append('non_polite')\n",
    "    tuple_head.append(tuple_temp)\n",
    "df_polite_train=pd.DataFrame(tuple_head,columns=['text','labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polite_train.to_csv('../HULK/Counterspeech/Datasets/Politeness/Train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_head=[]\n",
    "for index,row in df_polite[df_polite['split']=='val'].iterrows():\n",
    "    tuple_temp=[row['txt']]\n",
    "    if(row['style']=='P_9'):\n",
    "        tuple_temp.append('polite')\n",
    "    else:\n",
    "        tuple_temp.append('non_polite')\n",
    "    tuple_head.append(tuple_temp)\n",
    "df_polite_val=pd.DataFrame(tuple_head,columns=['text','labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polite_val.to_csv('../HULK/Counterspeech/Datasets/Politeness/Val.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_head=[]\n",
    "for index,row in df_polite[df_polite['split']=='test'].iterrows():\n",
    "    tuple_temp=[row['txt']]\n",
    "    if(row['style']=='P_9'):\n",
    "        tuple_temp.append('polite')\n",
    "    else:\n",
    "        tuple_temp.append('non_polite')\n",
    "    tuple_head.append(tuple_temp)\n",
    "df_polite_test=pd.DataFrame(tuple_head,columns=['text','labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polite_test.to_csv('../HULK/Counterspeech/Datasets/Politeness/Test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_polite_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('../HULK/Counterspeech/Datasets/Humour/train.csv')\n",
    "df_test=pd.read_csv('../HULK/Counterspeech/Datasets/Humour/dev.csv')\n",
    "df_total=pd.read_csv('../HULK/Counterspeech/Datasets/Humour/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=[]\n",
    "\n",
    "for index,row in df_train.iterrows():\n",
    "    if(row['humor']==True):\n",
    "        label.append('humor')\n",
    "    else:\n",
    "        label.append('non-humor')\n",
    "        \n",
    "df_train['labels']=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=[]\n",
    "\n",
    "for index,row in df_test.iterrows():\n",
    "    if(row['humor']==True):\n",
    "        label.append('humor')\n",
    "    else:\n",
    "        label.append('non-humor')\n",
    "        \n",
    "df_test['labels']=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test = train_test_split(df_test, test_size=0.5,random_state=42,stratify=df_test['labels'])\n",
    "df_train.to_csv('../HULK/Counterspeech/Datasets/Humour/Train.csv',index=False)\n",
    "X_test.to_csv('../HULK/Counterspeech/Datasets/Humour/Test.csv',index=False)\n",
    "X_val.to_csv('../HULK/Counterspeech/Datasets/Humour/Val.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data generation save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the CONAN, Reddit/Gab dataset, create debate dataset \n",
    "### Columns - id, initiator_message, reply_message\n",
    "import json\n",
    "with open('../HULK/Counterspeech/Datasets/Create_debate/selected_arguments.json', 'r') as fp:\n",
    "        dict_urls=json.load(fp)\n",
    "        \n",
    "total_data_sentences=[]\n",
    "for key in dict_urls:\n",
    "    dict_temp=dict_urls[key]['selected_arguments']\n",
    "    \n",
    "    stance=[]\n",
    "    for ele in dict_temp:\n",
    "        stance.append(ele['reply_stance'])\n",
    "    \n",
    "    stance=list(set(stance))\n",
    "    \n",
    "    for ele in dict_temp:\n",
    "        ele['title']=dict_urls[key]['title']\n",
    "        ele['stance_list']=stance\n",
    "        total_data_sentences.append(ele)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_sentences[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(total_data_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test_dev = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_test, X_dev = train_test_split(X_test_dev, test_size=0.5, random_state=42, shuffle=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('../HULK/Counterspeech/Datasets/Create_debate/Train.csv')\n",
    "X_dev.to_csv('../HULK/Counterspeech/Datasets/Create_debate/Val.csv')\n",
    "X_test.to_csv('../HULK/Counterspeech/Datasets/Create_debate/Test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../HULK/Counterspeech/Datasets/Reddit/reddit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit Data preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Data Input and Preprocessing which is data specific\n",
    "data = pd.read_csv('../HULK/Counterspeech/Datasets/Gab/gab.csv')\n",
    "data_mod = pd.DataFrame([[]])\n",
    "\n",
    "for row in range(len(data[\"id\"])):\n",
    "    #print(data[\"id\"][row])\n",
    "    data[\"id\"][row]=(data[\"id\"][row].splitlines())\n",
    "    for num in range(len(data[\"id\"][row])):\n",
    "        strin=''.join(data[\"id\"][row][num].split())\n",
    "        newstr='';\n",
    "        for i in range(len(strin)-2):\n",
    "            newstr+=strin[i+2]\n",
    "        data[\"id\"][row][num]=newstr\n",
    "\n",
    "for row in range(len(data[\"hate_speech_idx\"])):\n",
    "        if data[\"hate_speech_idx\"][row]=='n/a':\n",
    "            data[\"hate_speech_idx\"][row]=\"[0]\"\n",
    "\n",
    "for row in range(len(data[\"hate_speech_idx\"])):\n",
    "        if data[\"hate_speech_idx\"][row]=='n/a':\n",
    "            data[\"hate_speech_idx\"][row]=\"[0]\"\n",
    "\n",
    "for row in range(len(data[\"hate_speech_idx\"])):\n",
    "        if isinstance(data[\"hate_speech_idx\"][row],float):\n",
    "            data[\"hate_speech_idx\"][row]=\"[0]\"  \n",
    "\n",
    "for row in range(len(data[\"response\"])):\n",
    "        if isinstance(data[\"response\"][row],float):\n",
    "            data[\"response\"][row]='This is normal'\n",
    "            \n",
    "for row in range(len(data[\"text\"])):\n",
    "    #print(data[\"id\"][row])\n",
    "    data[\"text\"][row]=(data[\"text\"][row].splitlines())\n",
    "    for num in range(len(data[\"text\"][row])):\n",
    "        strin=' '.join(data[\"text\"][row][num].split())\n",
    "        newstr='';\n",
    "        for i in range(len(strin)-2):\n",
    "            newstr+=strin[i+2]\n",
    "        data[\"text\"][row][num]=newstr\n",
    "    \n",
    "    data[\"hate_speech_idx\"][row]=data[\"hate_speech_idx\"][row].strip('][').split(', ');\n",
    "    data[\"hate_speech_idx\"][row]=list(map(int, data[\"hate_speech_idx\"][row]))\n",
    "    data[\"response\"][row] = data[\"response\"][row].replace(\"\\\"\",\"\\'\")\n",
    "    data[\"response\"][row] = data[\"response\"][row].replace(\"[\\'\",\"\")\n",
    "    data[\"response\"][row] = data[\"response\"][row].replace(\"\\']\",\"\")\n",
    "    data[\"response\"][row] = data[\"response\"][row].split('\\', \\'');\n",
    "    \n",
    "    for idx in data[\"hate_speech_idx\"][row]:\n",
    "        if idx!=0 and idx<=len(data[\"text\"][row]):\n",
    "            bad=idx-1;\n",
    "#            print(bad)\n",
    "            for resp in data[\"response\"][row]:\n",
    "                newrow=pd.Series([data[\"text\"][row][bad],resp])\n",
    "                rowdf=pd.DataFrame([newrow])\n",
    "                data_mod=pd.concat([data_mod,rowdf],ignore_index=True)\n",
    "                #print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mod=data_mod[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mod.columns=['initiator_message','reply_message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mod=data_mod[(data_mod['reply_message']!='NA') & (data_mod['reply_message']!='n/a') & (data_mod['reply_message']!='N/A') & (data_mod['initiator_message']!='') & (data_mod['reply_message']!='')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test_dev = train_test_split(data_mod, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_test, X_dev = train_test_split(X_test_dev, test_size=0.5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[9166]['reply_message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('../HULK/Counterspeech/Datasets/Gab/Train.csv')\n",
    "X_dev.to_csv('../HULK/Counterspeech/Datasets/Gab/Val.csv')\n",
    "X_test.to_csv('../HULK/Counterspeech/Datasets/Gab/Test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_json('../HULK/Counterspeech/Datasets/CONAN/CONAN.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['cn_id'].str.contains(\"EN\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df[['cn_id','hateSpeech','counterSpeech']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.columns=['cn_id','initiator_message','reply_message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test_dev = train_test_split(df_new, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_test, X_dev = train_test_split(X_test_dev, test_size=0.5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('../HULK/Counterspeech/Datasets/CONAN/Train.csv')\n",
    "X_dev.to_csv('../HULK/Counterspeech/Datasets/CONAN/Val.csv')\n",
    "X_test.to_csv('../HULK/Counterspeech/Datasets/CONAN/Test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONAN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-csgen] *",
   "language": "python",
   "name": "conda-env-.conda-csgen-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
