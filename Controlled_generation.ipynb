{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from Generation.models import *\n",
    "from transformers import (\n",
    "    GPT2Config,\n",
    "    GPT2Tokenizer\n",
    ")\n",
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no logit scale or bias initialized for gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Model_Generation were not initialized from the model checkpoint at microsoft/DialoGPT-medium and are newly initialized: ['transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.12.attn.masked_bias', 'transformer.h.13.attn.masked_bias', 'transformer.h.14.attn.masked_bias', 'transformer.h.15.attn.masked_bias', 'transformer.h.16.attn.masked_bias', 'transformer.h.17.attn.masked_bias', 'transformer.h.18.attn.masked_bias', 'transformer.h.19.attn.masked_bias', 'transformer.h.20.attn.masked_bias', 'transformer.h.21.attn.masked_bias', 'transformer.h.22.attn.masked_bias', 'transformer.h.23.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config and bias\n"
     ]
    }
   ],
   "source": [
    "cache_dir='../HULK_new/Saved_models/'\n",
    "\n",
    "\n",
    "#gen_model_name_or_path='../HULK_new/Counterspeech/Saved_Models/Generator/Create_debate_DialoGPT-medium/'\n",
    "#gen_model_name_or_path='../HULK_new/Counterspeech/Saved_Models/Generator/CONAN_DialoGPT-medium/'\n",
    "gen_model_name_or_path='microsoft/DialoGPT-medium'\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(gen_model_name_or_path, cache_dir=cache_dir)\n",
    "model = Model_Generation.from_pretrained(gen_model_name_or_path,cache_dir=cache_dir)\n",
    "#model = model.to(device)\n",
    "model = model.float()\n",
    "\n",
    "gedi_model_name_or_path = '../HULK_new/Counterspeech/Saved_Models/Discriminator/Toxicity_gedi_gpt2_toxic/'\n",
    "gedi_model = Model_Generation.from_pretrained(gedi_model_name_or_path,cache_dir=cache_dir)\n",
    "#gedi_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'sep_token':'<|endoftext|>',\n",
    "    'max_generation_length': 80,\n",
    "    'min_generation_length':40,\n",
    "    'max_input_length':128,\n",
    "    'num_beams':1,\n",
    "    'no_repeat_ngram_size':5,\n",
    "    'repitition_penalty': 1.5,\n",
    "    'control_type':'gedi',\n",
    "    'k':100,\n",
    "    'p':0.92,\n",
    "    'filter_p':0.9,\n",
    "    'target_p':0.9,\n",
    "    'disc_weight':30,\n",
    "    'class_bias':0,\n",
    "    'sample':True,\n",
    "    'temperature':1.0,\n",
    "    'early_stopping':True,\n",
    "    'model_path':'gpt2-medium',\n",
    "    'dataset_hate':'CONAN',\n",
    "    'task_name':[('Emotion','joy')],\n",
    "    'coefficient':[4.5],\n",
    "    'save_path': './../HULK_new/Counterspeech/Results/',\n",
    "    'device': 'cuda',\n",
    "    'batch_size':4,\n",
    "    'cache_path':'./../HULK_new/Saved_models/',\n",
    "    'generation_method':'huggingface',\n",
    "    'class_bias':0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside own function\n",
      "torch.Size([1, 7])\n",
      "==============================\n",
      "tensor([40])\n",
      "tensor([40])\n",
      "==============================\n",
      "==============================\n",
      "tensor([466])\n",
      "tensor([466])\n",
      "==============================\n",
      "==============================\n",
      "tensor([428])\n",
      "tensor([428])\n",
      "==============================\n",
      "==============================\n",
      "tensor([326])\n",
      "tensor([326])\n",
      "==============================\n",
      "==============================\n",
      "tensor([345])\n",
      "tensor([[7942, 5195,  318,  340,  326]])\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([790])\n",
      "==============================\n",
      "==============================\n",
      "tensor([996])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([996])\n",
      "==============================\n",
      "==============================\n",
      "tensor([345])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([314])\n",
      "==============================\n",
      "==============================\n",
      "tensor([766])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([766])\n",
      "==============================\n",
      "==============================\n",
      "tensor([27257])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([27257])\n",
      "==============================\n",
      "==============================\n",
      "tensor([345])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([257])\n",
      "==============================\n",
      "==============================\n",
      "tensor([9811])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([2912])\n",
      "==============================\n",
      "==============================\n",
      "tensor([837])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([837])\n",
      "==============================\n",
      "==============================\n",
      "tensor([837])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([837])\n",
      "==============================\n",
      "==============================\n",
      "tensor([428])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([428])\n",
      "==============================\n",
      "==============================\n",
      "tensor([11783])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([11783])\n",
      "==============================\n",
      "==============================\n",
      "tensor([837])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([837])\n",
      "==============================\n",
      "==============================\n",
      "tensor([374])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([374])\n",
      "==============================\n",
      "==============================\n",
      "tensor([837])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([837])\n",
      "==============================\n",
      "==============================\n",
      "tensor([314])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([340])\n",
      "==============================\n",
      "==============================\n",
      "tensor([651])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([991])\n",
      "==============================\n",
      "==============================\n",
      "tensor([651])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([651])\n",
      "==============================\n",
      "==============================\n",
      "tensor([351])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([351])\n",
      "==============================\n",
      "==============================\n",
      "tensor([866])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([866])\n",
      "==============================\n",
      "==============================\n",
      "tensor([340])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([340])\n",
      "==============================\n",
      "==============================\n",
      "tensor([5633])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([5633])\n",
      "==============================\n",
      "==============================\n",
      "tensor([50256])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([50256])\n",
      "==============================\n",
      "==============================\n",
      "tensor([11040])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([11040])\n",
      "==============================\n",
      "==============================\n",
      "tensor([484])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([484])\n",
      "==============================\n",
      "==============================\n",
      "tensor([764])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([764])\n",
      "==============================\n",
      "==============================\n",
      "tensor([50256])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([50256])\n",
      "==============================\n",
      "==============================\n",
      "tensor([588])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([588])\n",
      "==============================\n",
      "==============================\n",
      "tensor([257])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([257])\n",
      "==============================\n",
      "==============================\n",
      "tensor([257])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([257])\n",
      "==============================\n",
      "==============================\n",
      "tensor([5629])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([5629])\n",
      "==============================\n",
      "==============================\n",
      "tensor([1517])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([1517])\n",
      "==============================\n",
      "==============================\n",
      "tensor([764])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([764])\n",
      "==============================\n",
      "==============================\n",
      "tensor([50256])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([50256])\n",
      "==============================\n",
      "==============================\n",
      "tensor([50256])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([50256])\n",
      "==============================\n",
      "==============================\n",
      "tensor([50256])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([50256])\n",
      "==============================\n",
      "==============================\n",
      "tensor([50256])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([50256])\n",
      "==============================\n",
      "==============================\n",
      "tensor([338])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([338])\n",
      "==============================\n",
      "==============================\n",
      "tensor([5633])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([5633])\n",
      "==============================\n",
      "==============================\n",
      "tensor([345])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([3783])\n",
      "==============================\n",
      "==============================\n",
      "tensor([5633])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([5633])\n",
      "==============================\n",
      "==============================\n",
      "tensor([50256])\n",
      "torch.Size([2, 50257])\n",
      "torch.Size([1, 50257])\n",
      "tensor([50256])\n",
      "==============================\n",
      "GeDi estimates the probability that it sample is desired class is: 0.946459949016571\n",
      "Prompt: I hate all niggers <|endoftext|>\n",
      "Reply: Why is it that even when I upvote a minority comment in r science or something, they still respond and defend it? Just so weird... Seems like such an unnecessary act. : O! What happened to racism?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"I hate all niggers <|endoftext|>\"\n",
    "\n",
    "start_len=0\n",
    "text_ids = tokenizer.encode(prompt)\n",
    "encoded_prompts=torch.LongTensor(text_ids).unsqueeze(0)\n",
    "# multi_code = tokenizer.encode(secondary_code)\n",
    "beam_outputs = model.generate(\n",
    "            controller_alphas=None,\n",
    "            controller_list=[gedi_model],\n",
    "            control_type='gedi',\n",
    "            positive_class='true',\n",
    "            negative_class='false',\n",
    "            tokenizer=tokenizer,\n",
    "            class_bias=params['class_bias'],\n",
    "            filter_p=params['filter_p'],\n",
    "            target_p=params['target_p'],\n",
    "            disc_weight=params['disc_weight'],\n",
    "            input_ids=encoded_prompts, \n",
    "            pad_token_id         = tokenizer.eos_token_id,\n",
    "            max_length           = params['max_generation_length']+len(encoded_prompts[0]),\n",
    "            min_length           = params['min_generation_length']+len(encoded_prompts[0]),\n",
    "            top_k                = params[\"k\"],\n",
    "            top_p                = params[\"p\"],\n",
    "            repetition_penalty   = params[\"repitition_penalty\"],\n",
    "            temperature          = params[\"temperature\"],\n",
    "            num_beams            = params['num_beams'], \n",
    "            do_sample            = params['sample'],\n",
    "            no_repeat_ngram_size = params['no_repeat_ngram_size'],  \n",
    "            early_stopping       = params['early_stopping']\n",
    "        )\n",
    "reply = (tokenizer.decode(beam_outputs[0])).split(params['sep_token'])[1]\n",
    "print(\"Prompt:\",prompt)\n",
    "print(\"Reply:\",reply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1639,   389,   257,  1928,  2475,   220, 50256]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-csgen] *",
   "language": "python",
   "name": "conda-env-.conda-csgen-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
